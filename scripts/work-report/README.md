## Work report generator

This folder contains a small tool that generates a work report from your recent git commits.

The main entry point is `scripts/work-report/generate_work_report.py`. It can:

- **Collect** commits since a given date (and optional author).
- **Deduplicate** likely backports / repeated commits.
- **Summarize** each commit into 1–5 sentences using an OpenAI‑compatible API (`details.md`).
- **Generate** a high‑level thematic report from those details (`report.md`).

The script is step‑based so you can use it even without any LLM access and still get the collected/deduped commits and the would‑be LLM prompts.

---

## Requirements

- **Python**: 3.9+ recommended.
- **Git**: `git` must be available on `PATH`.
- **Python packages**:
  - `openai` (required for steps that call the LLM).
  - `python-dotenv` (optional, for loading a `.env` file).

Install the Python dependencies (for example in your virtualenv):

```bash
pip install openai python-dotenv
```

---

## API configuration (OpenAI‑compatible)

The script follows the same configuration pattern as `scripts/test_openai_api.py`:

- **CLI arguments** (highest priority):
  - `--base-url`
  - `--model`
  - `--api-key`
- **Environment variables**:
  - `OPENAI_BASE_URL` or `BASE_URL`
  - `OPENAI_MODEL` or `MODEL`
  - `OPENAI_API_KEY` or `API_KEY`
- **`.env` file** (lowest priority):
  - `OPENAI_BASE_URL`
  - `OPENAI_MODEL`
  - `OPENAI_API_KEY`

Resolution order is: CLI args → environment variables → `.env` file.

The `.env` file is searched:

- In the directory of this script.
- In its parent directory.
- Or, as a fallback, via `load_dotenv()` with no explicit path.

If you only want to run the **collection** step, you do **not** need any API configuration and the `openai` package is not required.

---

## Command‑line interface

The core script is:

```bash
python scripts/work-report/generate_work_report.py [OPTIONS]
```

### Required arguments

- **`--since`**  
  Lower bound for commit dates, passed to `git log --since`.
  - Examples:
    - `--since 2024-12-01`
    - `--since "2 weeks ago"`

### Optional arguments

- **`--author`**  
  Filter commits by author, passed to `git log --author`.  
  Example: `--author "cermak@espressif.com"`.

- **`--repo-path`**  
  Path to the git repository to scan.  
  Default: current directory (`.`).

- **`--output-dir`**  
  Directory where all outputs will be written (`details.md`, `report.md`, JSON files, etc.).  
  Default: current working directory.

- **`--step`**  
  Which pipeline step to run:
  - `collect`: only collect and deduplicate commits, no LLM calls.
  - `details`: generate `details.md` from stored commits.
  - `report`: generate `report.md` from an existing `details.md`.
  - `all`: run `collect` → `details` → `report`.  
  Default: `all`.

- **`--dump-llm-input`**  
  When used with `--step collect`, additionally write a markdown file containing the exact prompts that would be sent to the LLM for each commit.

- **API‑related options** (can be omitted if using env vars / `.env`):
  - `--base-url URL` – API base URL (e.g. `https://api.openai.com/v1`).
  - `--model MODEL` – model name (e.g. `gpt-4.1-mini`).
  - `--api-key KEY` – API key.

---

## Outputs

All outputs are written into `--output-dir` (default: current working directory).

- **`commits_raw.json`** (collect step)  
  - List of all commits matching `--since` / `--author`, before deduplication.  
  - Each entry has:
    - `hash`
    - `date`
    - `subject`
    - `body`

- **`commits_deduped.json`** (collect step)  
  - Same structure as `commits_raw.json`, but after deduplication.  
  - Deduplication groups commits by:
    - Normalized subject (lower‑cased, trimmed, trailing punctuation removed, whitespace collapsed).
    - Commit body content.
  - The most recent commit in each group is kept.

- **`commits_deduped.md`** (collect step)  
  - Human‑readable markdown list of deduplicated commits:
    - One section per commit.
    - Shows hash, date, and body as a code block (if present).

- **`llm_details_input.md`** (collect step, only when `--dump-llm-input` is set)  
  - Markdown file that contains, for each deduped commit, the full prompt that would be sent to the LLM in the **details** step.
  - Useful to verify the LLM inputs without actually calling the API.

- **`details.md`** (details step)  
  - Generated by the LLM.  
  - Structure:
    - Top‑level title like `# Commit details since <date>`.
    - For each deduped commit:
      - `## <commit subject>`
      - Hash and date metadata.
      - A 1–5 sentence summary describing:
        - What changed technically.
        - Why the change was made.
        - Any user‑facing or developer‑impacting consequences.

- **`report.md`** (report step)  
  - Generated by the LLM from `details.md`.  
  - High‑level thematic summary suitable for a status/work report:
    - Grouped into sections (e.g., Networking, Documentation, CI, Bug fixes, Features).
    - Focuses on impact and themes rather than listing every commit.

---

## Typical workflows

### 1. Collect and inspect commits (no LLM required)

- **Goal**: Get structured + human‑readable view of your commits, and see what would be sent to the LLM later.

Example:

```bash
python scripts/work-report/generate_work_report.py \
  --since 2024-12-01 \
  --author "cermak@espressif.com" \
  --repo-path /path/to/esp-idf \
  --output-dir /home/david/repos/mind-lab/scripts/work-report \
  --step collect \
  --dump-llm-input
```

This will:

- **Not** require `openai` or any API configuration.
- Produce:
  - `commits_raw.json`
  - `commits_deduped.json`
  - `commits_deduped.md`
  - `llm_details_input.md`

You can then open `commits_deduped.md` and `llm_details_input.md` to confirm that:

- The deduplication behaves as you expect (backports grouped together, etc.).
- The commit prompts going into the LLM look reasonable.

### 2. Generate `details.md` (LLM summaries per commit)

Once you are happy with the collected/deduped commits, configure your API (via CLI, env vars, or `.env`) and run:

```bash
export OPENAI_BASE_URL=https://api.openai.com/v1
export OPENAI_MODEL=gpt-4.1-mini
export OPENAI_API_KEY=sk-...

python scripts/work-report/generate_work_report.py \
  --since 2024-12-01 \
  --author "cermak@espressif.com" \
  --repo-path /path/to/esp-idf \
  --output-dir /home/david/repos/mind-lab/scripts/work-report \
  --step details
```

The script will:

- Load deduplicated commits from `commits_deduped.json` in `--output-dir`.
- Call `client.chat.completions.create(...)` from the `openai` library for each commit.
- Write `details.md` with one section per commit containing a 1–5 sentence summary.

### 3. Generate `report.md` (thematic work report)

With `details.md` prepared, run:

```bash
python scripts/work-report/generate_work_report.py \
  --since 2024-12-01 \
  --output-dir /home/david/repos/mind-lab/scripts/work-report \
  --step report
```

The script will:

- Read `details.md` from `--output-dir`.
- Build a markdown prompt that asks the LLM to synthesize the details into a thematic report.
- Call the same OpenAI‑compatible chat API.
- Write the final `report.md` in `--output-dir`.

### 4. Run everything in one go

If you already trust the collection/dedup logic and your API configuration, you can run all steps in a single command:

```bash
python scripts/work-report/generate_work_report.py \
  --since 2024-12-01 \
  --author "cermak@espressif.com" \
  --repo-path /path/to/esp-idf \
  --output-dir /home/david/repos/mind-lab/scripts/work-report \
  --step all
```

This will:

- Collect & deduplicate commits.
- Call the LLM to generate `details.md`.
- Call the LLM again to generate `report.md`.

---

## Implementation notes

- **No agent frameworks**: the script uses direct calls to the `openai` client:
  - `client = OpenAI(base_url=..., api_key=...)`
  - `client.chat.completions.create(model=..., messages=[...])`
- **Deduplication**:
  - Normalizes subjects and groups commits by `(normalized_subject, body)` to reduce backport noise.
  - Keeps the last commit in each group and preserves the original chronological order in the outputs.
- **Failure modes**:
  - `--step collect` exits with a non‑zero code if `git log` fails.
  - LLM‑using steps report API errors to stderr and either skip that commit (for details) or abort (for report).

Use this script as a foundation; you can further tune prompts, dedup heuristics, and report structure as your workflow evolves.


